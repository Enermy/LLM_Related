# LLM_Related
分享一些大模型相关的工具和知识，并手把手介绍如何使用

### 大模型性能评估工具
EvalScope：
是魔搭社区倾力打造的模型评测与性能基准测试框架，为您的模型评估需求提供一站式解决方案。无论您在开发什么类型的模型，EvalScope 都能满足您的需求：

🧠 大语言模型

🎨 多模态模型

🔍 Embedding 模型

🏆 Reranker 模型

🖼️ CLIP 模型

🎭 AIGC模型（图生文/视频）

。。。

https://github.com/Enermy/LLM_Related/tree/main/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B-evalscore

deepeval：深度评估（DeepEval） 是一个专为大型语言模型（LLM）输出评测设计的开源框架。它借鉴了Pytest的设计理念，但更加专注于单元测试LLM生成的答案，确保其质量符合预期标准。通过集成最新的研究，如G-Eval等评价方法，DeepEval提供了一系列指标来量化LLM响应的准确性、相关性和其他关键特性。此外，该框架具有高度模块化，便于使用者选择性地运用其内置指标，或是开发自定义评估逻辑，适用于多样化的应用场景。

https://github.com/Enermy/LLM_Related/tree/main/deepeval
